
# -*- coding: utf-8 -*-

# è¯·è¾“å…¥ä»¥ä¸‹å‘½ä»¤å¯åŠ¨å‰ç«¯
# export PATH="$PATH:/home/nvidia/.local/bin"
# streamlit run chat_bot.py --server.port 5000
# å¤–ç½‘ç«¯å£ï¼šhttp://36.150.110.74:9519/

from ui_methods import *
import parse_pdf

path = '/home/nvidia/aws_hackathon_demo/krame'

# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º ERRORï¼Œè¿™æ ·åªä¼šæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œå¿½ç•¥è­¦å‘Š
logging.getLogger("streamlit").setLevel(logging.ERROR)
allow_multi_modal = True

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'counter' not in st.session_state:
    st.session_state.counter = 0
if st.session_state.counter == 0:
    recovery_list = []
    with open('data.pkl', 'wb') as f:
        pickle.dump(recovery_list, f)
    st.session_state.counter = 1
else:
    try:
        with open('data.pkl', 'rb') as f:
            recovery_list = pickle.load(f)  # {'role':'user/assistant','type':'string/pic',content:''}
    except FileNotFoundError:
        st.error('æœªæ‰¾åˆ° data.pkl æ–‡ä»¶')
        recovery_list = []

# åˆå§‹åŒ–ä¸»ç•Œé¢
st.title("å¡æ‹‰ç±³ã®DEMO")
st.write("æˆ‘çš„ç¬¬ä¸€ä¸ªä¸“å±æœºå™¨äººï¼Œå®ƒå¯ä»¥å›ç­”ä½ çš„é—®é¢˜ï¼Œä¹Ÿå¯ä»¥å’Œä½ èŠå¤©ã€‚")

logo_display(path)
background_set()
hide_streamlit_header_footer()
display_existing_messages(recovery_list)

llm_model="deepseek-ai/deepseek-r1"
embedding_model="baai/bge-m3"
vector_db_path="/home/nvidia/aws_hackathon_demo/vdb"

bot = RAGCarAdvisor(llm_model=llm_model, embedding_model=embedding_model, vector_db_path=vector_db_path)
# åˆå§‹åŒ–ä¾§è¾¹æ 
st.sidebar.header("å…¶ä»–åŠŸèƒ½")

st.sidebar.subheader("å‘é‡æ•°æ®åº“å»ºåº“")

if st.sidebar.button('æ‰§è¡Œ', help='å‘é‡æ•°æ®åº“å»ºåº“'):
    # **åœ¨ä¸‹é¢æ·»åŠ å‘é‡åº“å»ºåº“å‡½æ•°**
    parse_pdf.main(folder_path=path+'/nvidia/wei-test-data/Bright16 Air', faiss_db_path=path+'/nvidia/vdb')
    message_text = "å‘é‡æ•°æ®åº“å»ºåº“æ‰§è¡ŒæˆåŠŸï¼"
    with st.chat_message('assistant'):
        message_placeholder = st.empty()
        full_response = ""
        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œé€å­—æ·»åŠ å­—ç¬¦
        for char in message_text:
            full_response += char
            # æ›´æ–°å ä½ç¬¦çš„å†…å®¹
            message_placeholder.markdown(full_response)
            # æ·»åŠ å»¶è¿Ÿï¼Œæ§åˆ¶è¾“å‡ºé€Ÿåº¦
            time.sleep(0.05)

    recovery_list.append({'role': 'assistant', 'type': "string", 'content': full_response})

uploaded_file = st.sidebar.file_uploader("å‘æœºå™¨äººä¼ å›¾", type=['png', 'jpg', 'jpeg', 'txt'])

# ä¸Šä¼ å›¾ç‰‡åŠŸèƒ½
if st.sidebar.button('ä¸Šä¼ ', help='æäº¤å›¾ç‰‡'):
    image = Image.open(uploaded_file)
    add_user_message_to_session(image, recovery_list)
    if allow_multi_modal:

        # save_path = /home/lab/nvidia/wei-test-data/Bright16 Air/'
        save_path = path+'/nvidia/wei-test-data/Bright16 Air/'
        save_name = generate_unique_time_string_with_uuid() + '.jpg'
        image.save(save_path + save_name)

        # æ­¤å¤„æ·»åŠ è¿”å›ä¿¡æ¯
        message_text = "æ”¶åˆ°å›¾ç‰‡å•¦ï¼"
        with st.chat_message('assistant'):
            # response = pic_recognize_response(image)

            message_placeholder = st.empty()
            full_response = ""
            # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œé€å­—æ·»åŠ å­—ç¬¦
            for char in message_text:
                full_response += char
                # æ›´æ–°å ä½ç¬¦çš„å†…å®¹
                message_placeholder.markdown(full_response)
                # æ·»åŠ å»¶è¿Ÿï¼Œæ§åˆ¶è¾“å‡ºé€Ÿåº¦
                time.sleep(0.05)

        recovery_list.append({'role': 'assistant', 'type': "string", 'content': full_response})

IMAGE_FOLDER = "/home/lab/krame/nvidia/process_chart"  # ä¿®æ”¹ä¸ºä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„

# ä¾§è¾¹æ ä¸Šä¼ æŒ‰é’®
if st.sidebar.button('åŠ è½½å›¾ç‰‡', help='ä»æ–‡ä»¶å¤¹åŠ è½½å›¾ç‰‡'):
    if os.path.exists(IMAGE_FOLDER):
        images = [f for f in os.listdir(IMAGE_FOLDER) if f.lower().endswith(('png', 'jpg', 'jpeg', 'gif'))]

        if images:
            for img_file in images:
                img_path = os.path.join(IMAGE_FOLDER, img_file)
                image = Image.open(img_path)

                # æ˜¾ç¤ºå›¾ç‰‡åœ¨èŠå¤©æ¡†
                with st.chat_message("assistant"):
                    message_placeholder = st.empty()
                    full_response = f"åŠ è½½å›¾ç‰‡ï¼š{img_file} ğŸ“·\n"

                    # é€å­—æ¨¡æ‹Ÿæµå¼è¾“å‡º
                    for char in full_response:
                        message_placeholder.markdown(full_response[:full_response.index(char) + 1])
                        time.sleep(0.05)  # æ§åˆ¶è¾“å‡ºé€Ÿåº¦

                    st.image(image, caption=img_file)  # æ˜¾ç¤ºå›¾ç‰‡

# è¾“å…¥æ¡†
query = st.chat_input("ä½ å¯ä»¥é—®æˆ‘ä»»ä½•ä½ æƒ³é—®çš„é—®é¢˜")
if query:
    add_user_message_to_session(query, recovery_list)  # å­˜å‚¨é—®å¥
    response = generate_assistant_response(query, recovery_list, bot)  # å›ç­”ç”Ÿæˆ

# å­˜å‚¨å¯¹è¯
with open('data.pkl', 'wb') as f:
    pickle.dump(recovery_list, f)
